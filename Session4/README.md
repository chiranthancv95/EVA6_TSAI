## EVA6 Session4 Assignment Folder

This assignment has been divided into two parts - 
Part 1 and Part 2

The following is the problem statement for the two parts.

##Assignment:
###PART 1[250]: Rewrite the whole excel sheet showing backpropagation. Explain each major step, and write it on Github. 
Use [0.3, 0.5, -0.2, 0.7, 0.1, -0.6, 0.3, -0.9] for [w1, w2, w3, w4, w5, w6, w7, w8] variables instead of the other variables used in the class 
Take a screenshot, and show that screenshot in the readme file
Excel file must be there for us to cross-check the image shown on readme (no image = no score)
Explain each major step
Show what happens to the error graph when you change the learning rate from [0.1, 0.2, 0.5, 0.8, 1.0, 2.0] 
Upload all this to GitHub and then write all above as part 1 of your README.md file. 
Submit details to S4 - Assignment QnA.<br>
###PART 2 [250]: We have considered many points in our last 4 lectures. Some of these we have covered directly and some indirectly. They are:
How many layers,
MaxPooling,
1x1 Convolutions,
3x3 Convolutions,
Receptive Field,
SoftMax,
Learning Rate,
Kernels and how do we decide the number of kernels?
Batch Normalization,
Image Normalization,
Position of MaxPooling,
Concept of Transition Layers,
Position of Transition Layer,
DropOut
When do we introduce DropOut, or when do we know we have some overfitting
The distance of MaxPooling from Prediction,
The distance of Batch Normalization from Prediction,
When do we stop convolutions and go ahead with a larger kernel or some other alternative (which we have not yet covered)
How do we know our network is not going well, comparatively, very early
Batch Size, and effects of batch size
etc (you can add more if we missed it here)
Refer to this code: COLABLINK
WRITE IT AGAIN SUCH THAT IT ACHIEVES
99.4% validation accuracy
You have used parameters exactly between 12000 to 18000
You can use anything from above you want. 
You have used exactly 19 epochs
Have used BN, Dropout, a Fully connected layer, have used GAP. 
Your Dropout must have 0.069 as the dropout value
Your batch size must be exactly 128
You must add random rotation to your images between -5 to +5 degrees.
To learn how to add different things we covered in this session, you can refer to this code: https://www.kaggle.com/enwei26/mnist-digits-pytorch-cnn-99 DONT COPY ARCHITECTURE, JUST LEARN HOW TO INTEGRATE THINGS LIKE DROPOUT, BATCHNORM, ETC.
This is a slightly time-consuming assignment, please make sure you start early. You are going to spend a lot of effort into running the programs multiple times
Once you are done, submit your results in S4-Assignment-Solution
You must upload your assignment to a public GitHub Repository. Create a folder called S4 in it, and add your iPynb code to it. THE LOGS MUST BE VISIBLE. Before adding the link to the submission make sure you have opened the file in an "incognito" window. 
If you misrepresent your answers, you will be awarded -100% of the score.
If you submit Colab Link instead of notebook uploaded on GitHub or redirect the GitHub page to colab, you will be awarded -50%
Submit details to S4 - Assignment QnA. 

